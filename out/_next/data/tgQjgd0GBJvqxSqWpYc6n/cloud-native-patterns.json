{"pageProps":{"post":{"id":"cloud-native-patterns","title":"Cloud Native Patterns","category":"book summary","description":"Cloud Native Patterns Summary","type":"notes","date":"Sat Oct 02 2021","contentHtml":"<p>Cloud = where it runs; Cloud-native = how it runs</p>\n<p>Modern apps need rapid iteration, fast releases, zero downtime and an increase in the volume and variety of devices that connect to it.</p>\n<p>Cloud-native applications remain stable even when the infra they're running on is constantly changing/failing</p>\n<h3>Chapter 2: Running Cloud-Native Applications in Production</h3>\n<p>In most orgs, getting software deployed to prod is challenging - process designed to reduce risk and improve efficiency has the opposite effect</p>\n<p>inconsistencies in artifacts, configuration, and environments lead to system instability</p>\n<p>goal should be easy and frequent releases into production</p>\n<p>continuous delivery = the newest possible version of the software is deployable at any time (trunk is always deployable)</p>\n<ul>\n<li>advantages: can deploy at any time (first mover advantage), allows you to gather feedback early. If you miss dates,\nyou can release less features</li>\n</ul>\n<p>traditional delivery = SDLC is front-loaded with development, followed by extensive testing and packaging</p>\n<ul>\n<li>disadvantages: if you miss dates, testing is compressed (at the expense of quality) or you push dates</li>\n</ul>\n<p>Before: tested extensively before going to production and were left scrambling on go-live.</p>\n<p>After: Plan for failure and intentionally create a retreat path to make failures non-events. Monitor for crashes, latency changes, changes in click-through rates, etc.</p>\n<h3>Chapter 3: The Platform for Cloud-Native Software</h3>\n<p>AWS uses commodity hardware to offer services at a lower price but with a higher rate of failure. Exposes primitives as a service.</p>\n<p>Google app engine doesnt provide raw access to resources.</p>\n<p>For cloud-native apps, operators are interested in the application and <em>not</em> the hosts the app is running on/directories involved</p>\n<p>The popularity of containers was driven by the need to support cloud-native applications. Multiple containers run on a single host sharing the host's operating system.</p>\n<p>The platform creates app instances, monitors application health, distributes app instances across the infrastructure, assigns IP addresses to the containers, dynamically routes to app instances, and injects configuration</p>\n<p>challenges of highly distributed architectures:</p>\n<ul>\n<li>coordinating configuration changes</li>\n<li>tracing/monitoring execution flows</li>\n<li>retry logic - circuit breakers prevent inadvertent internal DDoS</li>\n<li>service discovery - each component needs to know URLs/IPs of all components it calls</li>\n<li>rolling upgrades</li>\n</ul>\n<p>each team is responsible for deployment, configuration, monitoring, scaling, and upgrading its products</p>\n<h3>Chapter 4: Event-Driven Microservices</h3>\n<p>Request-response = procedural/top-down - service request waits for responses from each dependent service and does some sort of aggregation to respond. Aggregation occurs in response to request.</p>\n<p>Event-driven = fire and forget - code execution has an effect and the outcome may cause other things to happen but the entity that triggered the execution doesnt expect a response. Aggregation occurs whenever data in the system changes - its asynchronous.</p>\n<p>Even-driven is less coupled and does not depend on other systems working correctly. Dependent services execute events to the aggregate service which maintains its own data store. Each service is independent of the other.</p>\n<p>Command Query Responsibility Segregation (CQRS) - separates write logic (commands) rom read logic (queries). Splitting controllers by read/write allows for different models on read/write.</p>\n<p>Events need message queues (RabbitMQ/Kafka) to store events through network partitions and handle downtimes in services</p>\n<p>https://github.com/cdavisafc/cloudnative-abundantsunshine</p>\n<h3>Chapter 5: App Redundancy: Scale-Out and Statelessness</h3>\n<p>Core tenant of cloud-native software is to have redundancy to avoid single points of failure. Apps should always have multiple instances deployed.</p>\n<p>Multiple instances should behave like a single logical entity.</p>\n<p>Multiple instances allow for flexible horizontal scaling, high availability, reliability, and operational efficiency.</p>\n<p>Kubernetes is a platform for running applications that includes capabilities that allow you to deploy, monitor, and scale your apps. Apps must be containerized to run in kubernetes.</p>\n<p>Instances must be stateless to allow for redundant deployment.</p>\n<p>CAP theorem - only two attributes of consistency, availability, and partition tolerance can be maintained.</p>\n<h3>Chapter 6: Application Configuration: Not just environment variables</h3>\n<p>Need a way to apply config to dynamic number of instances where infrastructure changes can cause config changes.</p>\n<p>Store config in the environment when possible. With spring, you can use the property file for defaults:</p>\n<div class=\"remark-highlight\"><pre class=\"language-unknown\"><code class=\"language-unknown\">ipaddress=${INSTANCE_IP:127.0.0.1}</code></pre></div>\n<p>Configuration data stores persists key/value pairs, maintains version history, and has access control mechanisms. Spring cloud config exposes config from a source code control system over an HTTP API. Sensitive values should be encrypted and stored by a service like Hashicorp Vault.</p>\n<h3>Chapter 7: The Application Lifecyle: Accounting for Constant Change</h3>\n<p>Management functions should be automatable, efficient, and reliable</p>\n<p>Platform needs a fail-safe way of detecting when an app failed</p>\n<p>App scales depending on load to safe cost - new apps are started/stopped all the time.</p>\n<p>Zero downtime deployments:</p>\n<ul>\n<li>blue/green deployment - stand up second set of instances, then switch traffic from first set to second set. All traffic is on the old or new version exclusively.</li>\n<li>rolling upgrade - replace a subset of instances with new instances. Different versions of the app will serve traffic at the same time temporarily.</li>\n<li>parallel deploys - different versions of the app serve traffic for as long as needed. Supports experimentation.</li>\n</ul>\n<p>For credential rotation across dependent services, make the provider accept two credentials temporarily (old + new), restart the app, then add the new credential to the client, restart the app, then remove the old credential from the provider.</p>\n<p>You should <em>not</em> be able to SSH into a production environment because doing so allows a way to make instances non reproducible.</p>\n<p>Treat logs as event streams</p>\n<ul>\n<li>write directly to stderr/stdout</li>\n<li>avoids need for log rotations or locating files in directories</li>\n</ul>\n<p>each service needs to broadcast events about its lifecycle - ip/port, etc</p>\n<ul>\n<li>publish health endpoints, kubernetes will call it continuously to detect crashed apps/app lifecycle. If its down, kubernetes will start a new instance. Can also be event-driven where you publish events.</li>\n</ul>\n<p>Serverless takes cloud-native to the extreme</p>\n<ul>\n<li>each call takes app through entire lifecycle</li>\n<li>dev needs to focus on making startup and execution as fast as possible</li>\n</ul>\n<h3>Chapter 8: Accessing Apps: Services, routing and service discovery</h3>\n"}},"__N_SSG":true}