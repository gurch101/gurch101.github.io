{"pageProps":{"post":{"id":"ml-2","title":"Advanced Learning Algorithms","category":"notes","description":"Coursera ML Specialization Course 2 Notes","type":"notes","date":"Thu Jan 14 2021","contentHtml":"<p>Neural networks</p>\n<ul>\n<li>inference/prediction</li>\n<li>training</li>\n<li>practical advice\nDecision trees</li>\n</ul>\n<p>Neural networks - algorithms that try to mimic the brain using simplified mathematical models of a neuron\nUsed for handwriting, speech recognition, image recognition, natural language processing</p>\n<p>A neural network has layers of neurons. Each neuron takes an input vector and outputs a single value.</p>\n<p>Can be thought of as logistic regression where each layer learns its own features. For example, in demand prediction,\ninputs could be price, shipping cost, marketing, material, output layer could engineer its own features of affordability, awareness, and perceived quality, which is then fed to another layer to output another set of features.</p>\n<p>For image recognition, pixel intensities are fed as a vector. Each layer indentifies increasingly complex features - lines, shapes, eyes/ears, etc.</p>\n<p><img src=\"/images/nnlayer.png\" alt=\"Neural Network Layer\"></p>\n<p>Forward propagation = prediction\nBackward propagation = learning</p>\n<p>Forward propagation in Python</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\">x <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span><span class=\"token number\">17</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nw1_1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb1_1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nz1_1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>w1_1<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b1_1\na1_1 <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>z1_1<span class=\"token punctuation\">)</span>\n\nw1_2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb1_2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nz1_2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>w1_2<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b1_2\na1_2 <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>z1_2<span class=\"token punctuation\">)</span>\n\nw1_3 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb1_3 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nz1_3 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>w1_3<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b1_3\na1_3 <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>z1_3<span class=\"token punctuation\">)</span>\n\na1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>a1_1<span class=\"token punctuation\">,</span> a1_2<span class=\"token punctuation\">,</span> a1_3<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># generic implementation</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">dense</span><span class=\"token punctuation\">(</span>a_in<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> g<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">  Computes dense layer</span>\n<span class=\"token triple-quoted-string string\">  Args:</span>\n<span class=\"token triple-quoted-string string\">    a_in (ndarray (n, )) : Data, 1 example</span>\n<span class=\"token triple-quoted-string string\">    W    (ndarray (n,j)) : Weight matrix, n features per unit, j units</span>\n<span class=\"token triple-quoted-string string\">    b    (ndarray (j, )) : bias vector, j units</span>\n<span class=\"token triple-quoted-string string\">    g    activation function (e.g. sigmoid, relu..)</span>\n<span class=\"token triple-quoted-string string\">  Returns</span>\n<span class=\"token triple-quoted-string string\">    a_out (ndarray (j,))  : j units|</span>\n<span class=\"token triple-quoted-string string\">  \"\"\"</span>\n  units <span class=\"token operator\">=</span> W<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># rows = number of features, columns = units</span>\n  a_out <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>units<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>units<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># if a,w,b were matrices, this loop could be replaced with Z = np.matmul(A_in,W) + b</span>\n    w <span class=\"token operator\">=</span> W<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span>j<span class=\"token punctuation\">]</span>\n    z <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> a_in<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span>\n    a_out<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> g<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> a_out\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">sequential</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> W1<span class=\"token punctuation\">,</span> b1<span class=\"token punctuation\">,</span> W2<span class=\"token punctuation\">,</span> b2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    a1 <span class=\"token operator\">=</span> dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>  W1<span class=\"token punctuation\">,</span> b1<span class=\"token punctuation\">,</span> sigmoid<span class=\"token punctuation\">)</span>\n    a2 <span class=\"token operator\">=</span> dense<span class=\"token punctuation\">(</span>a1<span class=\"token punctuation\">,</span> W2<span class=\"token punctuation\">,</span> b2<span class=\"token punctuation\">,</span> sigmoid<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>a2<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Tensorflow</h3>\n<p>Machine learning package from Google. Keras creates a simple, layer-centric interface to Tensorflow.</p>\n<p><img src=\"/images/tensorflowinference.png\" alt=\"Tensorflow Inference\"></p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Input\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses <span class=\"token keyword\">import</span> MeanSquaredError<span class=\"token punctuation\">,</span> BinaryCrossentropy\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>activations <span class=\"token keyword\">import</span> sigmoid\n<span class=\"token keyword\">import</span> logging\nlogging<span class=\"token punctuation\">.</span>getLogger<span class=\"token punctuation\">(</span><span class=\"token string\">\"tensorflow\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setLevel<span class=\"token punctuation\">(</span>logging<span class=\"token punctuation\">.</span>ERROR<span class=\"token punctuation\">)</span>\ntf<span class=\"token punctuation\">.</span>autograph<span class=\"token punctuation\">.</span>set_verbosity<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n\nX_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>           <span class=\"token comment\">#(size in 1000 square feet)</span>\nY_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">300.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">500.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>       <span class=\"token comment\">#(price in 1000s of dollars)</span>\n\n\n<span class=\"token comment\"># layer with one neuron using linear regression</span>\nlinear_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'linear'</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># initializes weights to random values. Tensorflow requires 2d matrices</span>\nlinear_layer<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nw<span class=\"token punctuation\">,</span> b<span class=\"token operator\">=</span> linear_layer<span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"w = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>w<span class=\"token punctuation\">}</span></span><span class=\"token string\">, b=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>b<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n\nset_w <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">200</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nset_b <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># set_weights takes a list of numpy arrays</span>\nlinear_layer<span class=\"token punctuation\">.</span>set_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>set_w<span class=\"token punctuation\">,</span> set_b<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># both produce identical values. a1 is a tensor. To convert back to a numpy array, call a1.numpy()</span>\na1 <span class=\"token operator\">=</span> linear_layer<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a1<span class=\"token punctuation\">)</span>\nalin <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>set_w<span class=\"token punctuation\">,</span>X_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> set_b\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>alin<span class=\"token punctuation\">)</span>\n\nprediction_tf <span class=\"token operator\">=</span> linear_layer<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">)</span>\nprediction_np <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span> X_train<span class=\"token punctuation\">,</span> set_w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> set_b\n\n\n<span class=\"token comment\"># Sequential is a list of nn layers</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> input_dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>  activation <span class=\"token operator\">=</span> <span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'L1'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># prints layers, type, shape, params</span>\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nlogistic_layer <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>get_layer<span class=\"token punctuation\">(</span><span class=\"token string\">'L1'</span><span class=\"token punctuation\">)</span>\nw<span class=\"token punctuation\">,</span>b <span class=\"token operator\">=</span> logistic_layer<span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\na1 <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a1<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># normalize the data</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Temperature Max, Min pre normalization: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Duration    Max, Min pre normalization: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\nnorm_l <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Normalization<span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nnorm_l<span class=\"token punctuation\">.</span>adapt<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># learns mean, variance</span>\nXn <span class=\"token operator\">=</span> norm_l<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Temperature Max, Min post normalization: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>Xn<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>Xn<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Duration    Max, Min post normalization: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>Xn<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>Xn<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">0.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>set_seed<span class=\"token punctuation\">(</span><span class=\"token number\">1234</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># applied to achieve consistent results</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        Dense<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'layer1'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'layer2'</span><span class=\"token punctuation\">)</span>\n     <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\n    loss <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>BinaryCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># run gradient descent</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\n    Xt<span class=\"token punctuation\">,</span>Yt<span class=\"token punctuation\">,</span>\n    epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># model.compile/model.fit(x,y) to train the model</span>\n</code></pre></div>\n<h3>Train a 0/1 Digit Recognizer</h3>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\">### Data Viz</span>\nm<span class=\"token punctuation\">,</span> n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n\nfig<span class=\"token punctuation\">,</span> axes <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nfig<span class=\"token punctuation\">.</span>tight_layout<span class=\"token punctuation\">(</span>pad<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span>ax <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>axes<span class=\"token punctuation\">.</span>flat<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Select random indices</span>\n    random_index <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Select rows corresponding to the random indices and</span>\n    <span class=\"token comment\"># reshape the image</span>\n    X_random_reshaped <span class=\"token operator\">=</span> X<span class=\"token punctuation\">[</span>random_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>T\n\n    <span class=\"token comment\"># Display the image</span>\n    ax<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>X_random_reshaped<span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Display the label above the image</span>\n    ax<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span>random_index<span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    ax<span class=\"token punctuation\">.</span>set_axis_off<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">### Train the model</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">25</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"my_model\"</span>\n<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\n    loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>BinaryCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\n    X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>\n    epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">### Visualize the results</span>\n\nm<span class=\"token punctuation\">,</span> n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n\nfig<span class=\"token punctuation\">,</span> axes <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nfig<span class=\"token punctuation\">.</span>tight_layout<span class=\"token punctuation\">(</span>pad<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>rect<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.03</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.92</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#[left, bottom, right, top]</span>\n\n<span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span>ax <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>axes<span class=\"token punctuation\">.</span>flat<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Select random indices</span>\n    random_index <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Select rows corresponding to the random indices and</span>\n    <span class=\"token comment\"># reshape the image</span>\n    X_random_reshaped <span class=\"token operator\">=</span> X<span class=\"token punctuation\">[</span>random_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>T\n\n    <span class=\"token comment\"># Display the image</span>\n    ax<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>X_random_reshaped<span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Predict using the Neural Network</span>\n    prediction <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>random_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">400</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> prediction <span class=\"token operator\">>=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">:</span>\n        yhat <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        yhat <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token comment\"># Display the label above the image</span>\n    ax<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>y<span class=\"token punctuation\">[</span>random_index<span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">,</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>yhat<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n    ax<span class=\"token punctuation\">.</span>set_axis_off<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfig<span class=\"token punctuation\">.</span>suptitle<span class=\"token punctuation\">(</span><span class=\"token string\">\"Label, yhat\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Neural Network Training</h3>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\"># 1. Initialize the model</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>Dense<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Dense<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 2. Compile the model with a loss function</span>\n<span class=\"token comment\"># this is the same as the logistic loss function</span>\n<span class=\"token comment\"># for regression, use MeanSquaredError()</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span>BinaryCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 3. Fit the model to the data by minimizing the cost function using backpropagation</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Activation Functions</h3>\n<p>Activation functions allow model fit more complex data</p>\n<p>Linear/no activation function:\nz = wx + b\nSigmoid:\n1/(1+e^-z)\nReLU:\nmax(0,Z)</p>\n<p><img src=\"/images/activationfns.png\" alt=\"Activation Functions\"></p>\n<p>For output layer:\nFor binary classification, choose sigmoid function (probability y = 1)\nFor regression problems, choose linear function (y can be + or -)\nFor regression problems where y can only be positive, choose ReLU</p>\n<p>For hidden layer:\nReLU is most common choice</p>\n<ul>\n<li>faster to compute</li>\n<li>faster to learn. flat in the left of the graph whereas sigmoid goes flat twice. Gradient descent is slower for sigmoid.</li>\n</ul>\n<p>If linear function was used for all layers, model is equivalent to linear regression\nIf hidden layers are all linear and output layer is sigmoid, model is equivalent to logistic regression</p>\n<h3>Multi-class Classification</h3>\n<p>classification with more than 2 labels. For example, identifying digits 0-9, identifying parts of speech.</p>\n<p>softmax is a generalization of logistic regression for multiclass classification</p>\n<p><img src=\"/images/softmax.png\" alt=\"Softmax\"></p>\n<p><img src=\"/images/softmaxgen.png\" alt=\"Generalized Softmax\"></p>\n<p>Smaller aj, bigger loss</p>\n<p><img src=\"/images/softmaxloss.png\" alt=\"Softmax Loss\"></p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">25</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'linear'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># each input only has one possible category</span>\n<span class=\"token comment\"># use from_logits=True to account for numerical roundoff error</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span>SparseCategoricalCrossEntropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">,</span>epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n\nlogit <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># gives probabilities</span>\nf_x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>logit<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">my_softmax</span><span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    ez <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span> <span class=\"token comment\"># element-wise exponential</span>\n    sm <span class=\"token operator\">=</span> ez<span class=\"token operator\">/</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>ez<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> sm\n</code></pre></div>\n<h3>Multi-label Classification</h3>\n<p>classification where each input can be associated with more than one label. For example, an image that has multiple different objects in it.</p>\n<p>Possible approaches:</p>\n<ul>\n<li>have separate neural networks for each object</li>\n<li>have one neural network with an output for each object. Each output unit has sigmoid activations.</li>\n</ul>\n<h3>Advanced Optimization</h3>\n<p>Adam algorithm (adaptive moment estimation) adjusts alpha (learning rate) to reach minimum faster. If parameters keeps moving in same direction, increase alpha. If parameters keep oscillating, decrease alpha.</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\"># tweak the learning rate to see which performs the best</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\nloss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Convolutional Layers</h3>\n<ul>\n<li>each neuron looks at part of the previous layers inputs rather than all of them (Dense).</li>\n<li>faster computation</li>\n<li>needs less training data and is less prone to overfitting</li>\n</ul>\n<h3>Debugging &#x26; Evaluation</h3>\n<p>Regression Evaluation</p>\n<ul>\n<li>split training set into training/test set. Fit params for training. Compute test error and training error. If jtrain is low and jtest is high, you have overfitting.</li>\n</ul>\n<p><img src=\"/images/modelevaluation.png\" alt=\"Model evaluation\"></p>\n<p>Classification Evaluation</p>\n<p><img src=\"/images/classificationevaluation.png\" alt=\"Classification evaluation\"></p>\n<p>Split training into training, cross-validation, and test sets. Create multiple models and minimize cost on the cross validation set. Use test set to estimate generalization error.</p>\n<p><img src=\"/images/crossvalidation.png\" alt=\"Cross validation\"></p>\n<p>If Jtrain and Jcv is high, then model has high bias and underfits</p>\n<p>If Jtrain is low and Jcv is high, then model has high variance and overfits</p>\n<p>If Jtrain is low and Jcv is low, then model generalizes</p>\n<p>If Jtrain is high and Jcv is higher, then model has high bias and high variance. Overfits for part of the data and underfits for part of the data.</p>\n<p><img src=\"/images/fitbydegree.png\" alt=\"Cost as a function of the polynomial degree\"></p>\n<p>With regularization, high lambda leads to high bias (model keeps weights ~= 0). Low lambda leads to overfitting. Choose lambda by slowly increasing it and compare Jcv/Jtrain for each execution.</p>\n<p><img src=\"/images/fitbylambda.png\" alt=\"Cost as a function of lambda\"></p>\n<p>Establish baseline error rate by comparing to human performance, competing algorithms, or guess based on experience</p>\n<p><img src=\"/images/fitbysize.png\" alt=\"Cost as a function of training set size\"></p>\n<p>For high bias, Jtrain error will be higher. Adding more training data will not bring down the error rate by itself.</p>\n<p>For high variance, Jtrain will be lower and gap between Jtrain and Jcv will be larger. Adding more train data can improve performance.</p>\n<p>Large neural networks for medium sized data sets are low bias machines. Can continue to increase the size of the network to improve training set performance. If it does not do well on the cross-validation set, get more data. A large neural network will usually do as well or better than a smaller one so long as regularization is chosen appropriately.</p>\n<p><img src=\"/images/nndebugging.png\" alt=\"Neural Network Debugging\"></p>\n<p>Neural network can be regularized in tensorflow with <code>kernel_regularizer=L2(0.01)</code> param for the layer.</p>\n<p>Possible Improvements</p>\n<p>If high variance:</p>\n<ul>\n<li>Get more training examples</li>\n<li>Try smaller sets of features</li>\n<li>increase lambda</li>\n</ul>\n<p>If high bias:</p>\n<ul>\n<li>Try adding polynomial features</li>\n<li>Get additional features</li>\n<li>decrease lambda</li>\n</ul>\n<h3>Development Process</h3>\n<ul>\n<li>Choose architecture, model, data, features</li>\n<li>Train model</li>\n<li>bias, variance, and error analysis</li>\n<li>repeat</li>\n</ul>\n<h3>Error Analysis</h3>\n<ul>\n<li>Look for common traits in misclassified cross validation examples. For example, for spam classification, some categories could be pharma-related, deliberate misspellings, unusual routing, phishing, spam in embedded images</li>\n<li>use common categories to add features or more data that belongs in certain categories</li>\n</ul>\n<h3>Adding Data</h3>\n<ul>\n<li>add more data of the types where error analysis has indicated it might help. Go to unlabeled data and find more examples of a specific category</li>\n<li>modify an existing training example to create a new training example (data augmentation). As an example, distort or transform image/audio of a number to create new examples.</li>\n<li>use artificial data imputs to create new training examples from scratch (data synthesis). As an example, use different fonts/colors to create new data for an OCR task.</li>\n</ul>\n<h3>Transfer Learning</h3>\n<p>Use a large model trained on something else (supervised pre-training). Keep input and hidden layers and their parameters. Replace output layer (fine tuning).</p>\n<p>Option 1: only train output layer parameters. Works better for small data sets.</p>\n<p>Option 2: train all parameters but initialize them using the original neural network parameters.</p>\n<p>For images, the thought is the hidden layers can recognize edges, corners, curves, and basic shapes which could be useful for other tasks.</p>\n<h3>Skewed Datasets</h3>\n<p>Skewed dataset - ratio to postiive/negative examples is not 1:1.</p>\n<p>IE rare disease classification:</p>\n<ul>\n<li>1% error on test set but in the real world, only 0.5% of patients have disease. 1% error on its own does not indicate good results.</li>\n</ul>\n<p>Compute counts of true positives, true negatives, false positives, false negatives</p>\n<p>Precision - of all examples, what fraction is actually positive? (true positives/(true positives + false positives)). High precision = high confidence of correctness.</p>\n<p>Recall - of all examples that are positive, what fraction were accurately predicted? (true positives/(true positives + false negatives)). High recall = high confidence of not missing positives.</p>\n<p>In an ideal case, we want high precision and high recall.</p>\n<p>For logistic regression, we can alter precision/recall by changing the prediction threshold (ie instead of 0.5, use 0.7). Raising the threshold results in higher precision but lower recall.</p>\n<p><img src=\"/images/skew.png\" alt=\"Precision vs Recall\"></p>\n<p>F1 score (harmonic mean) can be used to choose algorithm with optimal precision/recall. F1 score takes an average while emphasizing the smaller number.</p>\n<p>F1 score = 1/(1/2(1/p + 1/r)) = 2pr/(p+r)</p>\n<h3>Decision Trees</h3>\n<p>Works well on tabular/structured data for classification or regression tasks. Not recommended for unstructured data (images, video, audio, text). Very fast to train.</p>\n<p>For each example, start at root node, go down path based on feature values until leaf node (output variable) is reached</p>\n<p>Decision tree algorithm \"learns\" the best decision tree of all possible decision trees.</p>\n<p>Learning Process:</p>\n<ol>\n<li>Choose feature for root node based on the feature that maximizes purity (or minimizes impurity)</li>\n<li>split examples based on node</li>\n<li>DFS for each node until examples are appropriately categorized or a maximum depth is reached or the purity score is below a threshold or when the number of examples in a node is below a threshold</li>\n</ol>\n<p>Entropy - measure of impurity</p>\n<p><img src=\"/images/entropy.png\" alt=\"entropy\"></p>\n<p>po = 1 - p1\nH(p1) = -p1log2(p1) - p0log2(p0)</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">compute_entropy</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Computes the entropy for</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">       y (ndarray): Numpy array indicating whether each example at a node is</span>\n<span class=\"token triple-quoted-string string\">           edible (`1`) or poisonous (`0`)</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">        entropy (float): Entropy at that node</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    entropy <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        p1 <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span>y <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> p1 <span class=\"token operator\">!=</span> <span class=\"token number\">0</span> <span class=\"token keyword\">and</span> p1 <span class=\"token operator\">!=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>p1 <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>log2<span class=\"token punctuation\">(</span>p1<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> p1<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>log2<span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> p1<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            entropy <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">return</span> entropy\n</code></pre></div>\n<p>Information gain</p>\n<p>choose a split by maximizing the reduction in the weighted average of the entropy for each possible feature</p>\n<p><img src=\"/images/infogain.png\" alt=\"Information Gain\"></p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">split_dataset</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> node_incices<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Splits the data at the given node into</span>\n<span class=\"token triple-quoted-string string\">    left and right branches</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">        X (ndarray):             Data matrix of shape(n_samples, n_features)</span>\n<span class=\"token triple-quoted-string string\">        node_indices (list):  List containing the active indices. I.e, the samples being considered at this step.</span>\n<span class=\"token triple-quoted-string string\">        feature (int):           Index of feature to split on</span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">        left_indices (list): Indices with feature value == 1</span>\n<span class=\"token triple-quoted-string string\">        right_indices (list): Indices with feature value == 0</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    left_indices <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    right_indices <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\">### START CODE HERE ###</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> node_indices<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            left_indices<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            right_indices<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">### END CODE HERE ###</span>\n\n    <span class=\"token keyword\">return</span> left_indices<span class=\"token punctuation\">,</span> right_indices\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_information_gain</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Compute the information of splitting the node on a given feature</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">        X (ndarray):            Data matrix of shape(n_samples, n_features)</span>\n<span class=\"token triple-quoted-string string\">        y (array like):         list or ndarray with n_samples containing the target variable</span>\n<span class=\"token triple-quoted-string string\">        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">        cost (float):        Cost computed</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n    <span class=\"token comment\"># Split dataset</span>\n    left_indices<span class=\"token punctuation\">,</span> right_indices <span class=\"token operator\">=</span> split_dataset<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Some useful variables</span>\n    X_node<span class=\"token punctuation\">,</span> y_node <span class=\"token operator\">=</span> X<span class=\"token punctuation\">[</span>node_indices<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">[</span>node_indices<span class=\"token punctuation\">]</span>\n    X_left<span class=\"token punctuation\">,</span> y_left <span class=\"token operator\">=</span> X<span class=\"token punctuation\">[</span>left_indices<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">[</span>left_indices<span class=\"token punctuation\">]</span>\n    X_right<span class=\"token punctuation\">,</span> y_right <span class=\"token operator\">=</span> X<span class=\"token punctuation\">[</span>right_indices<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">[</span>right_indices<span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># You need to return the following variables correctly</span>\n    information_gain <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    node_entropy <span class=\"token operator\">=</span> compute_entropy<span class=\"token punctuation\">(</span>y_node<span class=\"token punctuation\">)</span>\n    left_entropy <span class=\"token operator\">=</span> compute_entropy<span class=\"token punctuation\">(</span>y_left<span class=\"token punctuation\">)</span>\n    right_entropy <span class=\"token operator\">=</span> compute_entropy<span class=\"token punctuation\">(</span>y_right<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Weights</span>\n    w_left <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_left<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_node<span class=\"token punctuation\">)</span>\n    w_right <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_right<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_node<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">#Weighted entropy</span>\n    weighted_entropy <span class=\"token operator\">=</span> w_left <span class=\"token operator\">*</span> left_entropy <span class=\"token operator\">+</span> w_right <span class=\"token operator\">*</span> right_entropy\n\n    <span class=\"token comment\">#Information gain</span>\n    information_gain <span class=\"token operator\">=</span> node_entropy <span class=\"token operator\">-</span> weighted_entropy\n\n    <span class=\"token keyword\">return</span> information_gain\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_best_split</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Returns the optimal feature and threshold value</span>\n<span class=\"token triple-quoted-string string\">    to split the node data</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">        X (ndarray):            Data matrix of shape(n_samples, n_features)</span>\n<span class=\"token triple-quoted-string string\">        y (array like):         list or ndarray with n_samples containing the target variable</span>\n<span class=\"token triple-quoted-string string\">        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">        best_feature (int):     The index of the best feature to split</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    <span class=\"token comment\"># Some useful variables</span>\n    num_features <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># You need to return the following variables correctly</span>\n    best_feature <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n\n    max_info_gain<span class=\"token operator\">=</span><span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> feature <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_features<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        info_gain <span class=\"token operator\">=</span> compute_information_gain<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> info_gain <span class=\"token operator\">></span> max_info_gain<span class=\"token punctuation\">:</span>\n            max_info_gain <span class=\"token operator\">=</span> info_gain\n            best_feature <span class=\"token operator\">=</span> feature\n\n    <span class=\"token keyword\">return</span> best_feature\n\ntree <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">build_tree_recursive</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">,</span> branch_name<span class=\"token punctuation\">,</span> max_depth<span class=\"token punctuation\">,</span> current_depth<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node.</span>\n<span class=\"token triple-quoted-string string\">    This function just prints the tree.</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">        X (ndarray):            Data matrix of shape(n_samples, n_features)</span>\n<span class=\"token triple-quoted-string string\">        y (array like):         list or ndarray with n_samples containing the target variable</span>\n<span class=\"token triple-quoted-string string\">        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.</span>\n<span class=\"token triple-quoted-string string\">        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right']</span>\n<span class=\"token triple-quoted-string string\">        max_depth (int):        Max depth of the resulting tree.</span>\n<span class=\"token triple-quoted-string string\">        current_depth (int):    Current depth. Parameter used during recursive call.</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    <span class=\"token comment\"># Maximum depth reached - stop splitting</span>\n    <span class=\"token keyword\">if</span> current_depth <span class=\"token operator\">==</span> max_depth<span class=\"token punctuation\">:</span>\n        formatting <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span><span class=\"token operator\">*</span>current_depth <span class=\"token operator\">+</span> <span class=\"token string\">\"-\"</span><span class=\"token operator\">*</span>current_depth\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>formatting<span class=\"token punctuation\">,</span> <span class=\"token string\">\"%s leaf node with indices\"</span> <span class=\"token operator\">%</span> branch_name<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token comment\"># Otherwise, get best split and split the data</span>\n    <span class=\"token comment\"># Get the best feature and threshold at this node</span>\n    best_feature <span class=\"token operator\">=</span> get_best_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">)</span>\n    tree<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>current_depth<span class=\"token punctuation\">,</span> branch_name<span class=\"token punctuation\">,</span> best_feature<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    formatting <span class=\"token operator\">=</span> <span class=\"token string\">\"-\"</span><span class=\"token operator\">*</span>current_depth\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%s Depth %d, %s: Split on feature: %d\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>formatting<span class=\"token punctuation\">,</span> current_depth<span class=\"token punctuation\">,</span> branch_name<span class=\"token punctuation\">,</span> best_feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Split the dataset at the best feature</span>\n    left_indices<span class=\"token punctuation\">,</span> right_indices <span class=\"token operator\">=</span> split_dataset<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> node_indices<span class=\"token punctuation\">,</span> best_feature<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># continue splitting the left and the right child. Increment current depth</span>\n    build_tree_recursive<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> left_indices<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Left\"</span><span class=\"token punctuation\">,</span> max_depth<span class=\"token punctuation\">,</span> current_depth<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    build_tree_recursive<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> right_indices<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Right\"</span><span class=\"token punctuation\">,</span> max_depth<span class=\"token punctuation\">,</span> current_depth<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>One-Hot Encoding</h3>\n<p>One-hot encoding is used for features that can take on multiple discrete values.</p>\n<p>Make each category its own boolean feature. IE ear shape of pointy, oval, floppy can be three features instead.</p>\n<p>If a categorical feature can take on k values, create k binary features (0 or 1)</p>\n<h3>Continuous Features</h3>\n<p>Split based on whether value is &#x3C;= some value. Consider multiple thresholds and use the one that produces the best information gain.</p>\n<p>Algorithm:</p>\n<ul>\n<li>sort by value</li>\n<li>use midpoint values as possible threshold</li>\n<li>choose max info gain value</li>\n</ul>\n<h3>Regression Trees</h3>\n<p>use input features to predict a continuous number. Take average of all output values in leaf node. Each node should attempt to maximize reduction in variance of output variable at each split.</p>\n<p><img src=\"/images/regressiontreesplit.png\" alt=\"regression tree split\"></p>\n<h3>Tree Ensembles</h3>\n<p>Decision trees are highly sensitive to small changes of the data. Changing one training example can completely change the tree. Tree ensembles can be used to make the trees more robust. Create multiple trees, run each example through each tree and use the majority result.</p>\n<p>Tree ensembles are constructed through sampling with replacement. Take m training examples at random and construct a tree with that data. Repeat this B times (64-128). Also known as a bagged decision tree.</p>\n<p>For random forests:</p>\n<p>At each node, when choosing a feature to use to split, if n features are available, pick a random subset of k &#x3C; n features and allow the algorithm to only choose from that subset of features. For a large number of features, use k = sqrt(n).</p>\n<p>For boosted trees:</p>\n<p>Use sampling with replacement to create a new training set of size m but instead of picking for all examples with equal (1/m) probability, make it more likely to pick examples that the previous trained trees misclassify (deliberate practice analogy).</p>\n<p>XGBoost (extreme gradient boosting)</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBClassifier\n\n<span class=\"token comment\"># Classification</span>\nmodel <span class=\"token operator\">=</span> XGBClassifier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Regression</span>\nmodel <span class=\"token operator\">=</span> XGBRegressor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\ny_pred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>tree <span class=\"token keyword\">import</span> DecisionTreeRegressor\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># get percentiles, mean, std of each column</span>\ndata<span class=\"token punctuation\">.</span>describe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># list all columns</span>\ndata<span class=\"token punctuation\">.</span>columns\n\n<span class=\"token comment\"># get predictive column</span>\ny <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>Price\n\n<span class=\"token comment\"># get features</span>\nX <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'Rooms'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Bathroom'</span><span class=\"token punctuation\">.</span> <span class=\"token string\">'Landsize'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># show first bunch of rows</span>\nX<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ntrain_X<span class=\"token punctuation\">,</span> val_X<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> val_y <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> random_state <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_mae</span><span class=\"token punctuation\">(</span>max_leaf_nodes<span class=\"token punctuation\">,</span> train_X<span class=\"token punctuation\">,</span> val_X<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> val_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># random_state ensures same results for each run, max_leaf_nodes is used to control tree depth</span>\n    <span class=\"token comment\"># too deep = overfitting, too shallow = underfitting</span>\n    model <span class=\"token operator\">=</span> DecisionTreeRegressor<span class=\"token punctuation\">(</span>random_state<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> max_leaf_nodes<span class=\"token operator\">=</span>max_leaf_nodes<span class=\"token punctuation\">)</span>\n    model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_X<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">)</span>\n    preds_val <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_X<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># abs(predicted - actual) / N</span>\n    mae <span class=\"token operator\">=</span> mean_absolute_error<span class=\"token punctuation\">(</span>val_y<span class=\"token punctuation\">,</span> preds_val<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>mae<span class=\"token punctuation\">)</span>\n\ncandidate_max_leaf_nodes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">25</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">250</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># Write loop to find the ideal tree size from candidate_max_leaf_nodes</span>\nscores <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span> leaf_size<span class=\"token punctuation\">:</span> get_mae<span class=\"token punctuation\">(</span>leaf_size<span class=\"token punctuation\">,</span> train_X<span class=\"token punctuation\">,</span> val_X<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> val_y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> leaf_size <span class=\"token keyword\">in</span> candidate_max_leaf_nodes<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)</span>\nbest_tree_size <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>scores<span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span>scores<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># now that all param decisions are made, fit to entire dataset</span>\nfinal_model <span class=\"token operator\">=</span> DecisionTreeRegressor<span class=\"token punctuation\">(</span>max_leaf_nodes<span class=\"token operator\">=</span>best_tree_size<span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\nfinal_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Random Forests</h3>\n<p>A random forest uses many trees and makes predictions by averaging the prediction of each tree</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>ensemble <span class=\"token keyword\">import</span> RandomForestRegressor\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error\n\nforest_model <span class=\"token operator\">=</span> RandomForestRegressor<span class=\"token punctuation\">(</span>random_state<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nforest_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_X<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">)</span>\nmelb_preds <span class=\"token operator\">=</span> forest_model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>mean_absolute_error<span class=\"token punctuation\">(</span>val_y<span class=\"token punctuation\">,</span> melb_preds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Questions</h3>\n<p>Why do neural networks use the sigmoid function? why not just raw vaules like linear regression?</p>\n<p>How many layers should I use? how many units per layer?</p>\n"}},"__N_SSG":true}