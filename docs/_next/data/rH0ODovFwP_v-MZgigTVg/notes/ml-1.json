{"pageProps":{"post":{"id":"ml-1","title":"Supervised Machine Learning - Regression and Classification","category":"notes","description":"Coursera ML Specialization Course 1 Notes","type":"notes","date":"Thu Jan 14 2021","contentHtml":"<p>Give computers the ability to learn without being explicitly programmed</p>\n<p>Supervised Learning</p>\n<ul>\n<li>used most in real-world applications and has seen rapid advancements</li>\n<li>algorithms that learn input to output mappings given input/output examples to learn from.</li>\n<li>regression: predict a number amongst infinitely many possible outputs\n<ul>\n<li>housing prices</li>\n</ul>\n</li>\n<li>classification: predict a finite number of categories\n<ul>\n<li>tumor classification</li>\n</ul>\n</li>\n</ul>\n<p>Unsupervised Learning</p>\n<ul>\n<li>given inputs but not outputs - goal is to find something interesting in unlabeled data</li>\n<li>recommender systems/reinforcement learning</li>\n<li>clustering: group together similar data\n<ul>\n<li>similar news articles</li>\n<li>DNA microarray clustering</li>\n<li>customer/market segmentation</li>\n</ul>\n</li>\n<li>anomaly detection: find unusual data points</li>\n<li>dimensionality reduction: compress data using fewer numbers</li>\n</ul>\n<h3>Linear Regression</h3>\n<ul>\n<li>\n<p>Plot data on x/y plot. Add line of best fit, use formula for line to predict other inputs.</p>\n</li>\n<li>\n<p>Also useful to put data in a table where inputs/outputs are separate columns.</p>\n</li>\n<li>\n<p>training set: input and output dataset used to train the model</p>\n</li>\n<li>\n<p>x = input variable/feature</p>\n</li>\n<li>\n<p>y = output variable/target</p>\n</li>\n<li>\n<p>m = number of training examples</p>\n</li>\n<li>\n<p>(x, y) = single training example</p>\n</li>\n<li>\n<p>w/b are model parameters (coefficients/weights)</p>\n</li>\n<li>\n<p>given a training set, and a learning algorithm, generate a function that can predict y given x</p>\n</li>\n<li>\n<p>fwb(x) = wx + b</p>\n</li>\n</ul>\n<h3>Sum of Squared Error</h3>\n<ul>\n<li>goal of cost function is to find w,b such that y prediction is close to y target for all (x,y)</li>\n<li>squared error cost function: J(w,b) = 1 / 2m * sum((ypred - ytarget) ^ 2)</li>\n<li>divide by 2m so that we dont get bigger errors for a larger training set. Using 2 makes the gradient descent derivative cleaner.</li>\n<li>square the error so that the sum doesnt go to zero when -ve/+ve errors are added together</li>\n<li>goal is to minimize J(w,b)</li>\n<li>a line in the model graph is a point on the cost graph</li>\n</ul>\n<p>Simple example where b = 0</p>\n<p><img src=\"/images/sse.png\" alt=\"Sum of Squared Errors Graph\"></p>\n<p>w and b - sum of squared error cost function for linear regression will always be bowl shaped\n<img src=\"/images/contour.png\" alt=\"Contour Graph\"></p>\n<h3>Gradient Descent</h3>\n<ul>\n<li>\n<p>Used to find w, b that minimizes J(w,b). Gradient descent can be used to minimize any function. Finds local minima.</p>\n</li>\n<li>\n<p>Algorithm:</p>\n<ul>\n<li>\n<p>start with some w,b (for linear regression, use 0,0)</p>\n</li>\n<li>\n<p>keep changing w,b to reduce J(w,b)</p>\n<ul>\n<li>w = w - a * d/dwJ(w,b)</li>\n<li>b = b - a * d/dbJ(w,b)</li>\n<li>a = learning rate (between 0 and 1). Controls the size of the \"step\" taken when changing a parameter</li>\n</ul>\n</li>\n<li>\n<p>repeat until w/b no longer change much</p>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/gradientdescent.png\" alt=\"Gradient Descent\"></p>\n<p><img src=\"/images/gradientdescentformula.png\" alt=\"Formula\"></p>\n<p>If the learning rate is too large, it might never converge and may get further from the minimum. If too small, it will take very long.</p>\n<p>Even when using a fixed learning rate, each update step is smaller since the slope is smaller as we approach the local minima.</p>\n<p>For sum of squared errors, gradient descent will always find the global minimum.</p>\n<p>Batch gradient descent looks at all training examples.</p>\n<p>To make sure gradient descent is converging, plot J (y axis) vs # iterations (x axis). This is known as the learning curve. If the cost sometimes goes up, the learning rate might be too large.</p>\n<p><img src=\"/images/learningcurve.png\" alt=\"Learning Curve\"></p>\n<p>Alternative: if cost decreases by &#x3C;= epsilon in one iteration, then declare convergence</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nx_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ny_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">300.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500.0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nw <span class=\"token operator\">=</span> <span class=\"token number\">200</span>\nb <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\ntmp_f_wb <span class=\"token operator\">=</span> compute_model_output<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> tmp_f_wb<span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Our Prediction'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'x'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Actual Values'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Housing Prices'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Price (in 1000s of dollars)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Size (1000 sqft)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_model_output</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># m is the number of training examples</span>\n    m <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># alt is len(x_train)</span>\n    f_wb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        f_wb<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> w <span class=\"token operator\">*</span> x<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b\n    <span class=\"token keyword\">return</span> f_wb\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_cost</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  m <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n  cost_sum <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    f_wb <span class=\"token operator\">=</span> w <span class=\"token operator\">*</span> x<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b\n    cost <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>f_wb <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">**</span> <span class=\"token number\">2</span>\n    cost_sum <span class=\"token operator\">=</span> cost_sum <span class=\"token operator\">+</span> cost\n  <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> cost_sum\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_gradient</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  m <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n  dj_dw <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  dj_db <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    f_wb <span class=\"token operator\">=</span> w <span class=\"token operator\">*</span> x<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b\n    dj_dw_i <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>f_wb <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> x<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n    dj_db_i <span class=\"token operator\">=</span> f_wb <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n    dj_db <span class=\"token operator\">+=</span> dj_db_i\n    dj_dw <span class=\"token operator\">+=</span> dj_dw_i\n  dj_dw <span class=\"token operator\">=</span> dj_dw<span class=\"token operator\">/</span>m\n  dj_db <span class=\"token operator\">=</span> dj_db<span class=\"token operator\">/</span>m\n  <span class=\"token keyword\">return</span> dj_dw<span class=\"token punctuation\">,</span> dj_db\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">gradient_descent</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w_in<span class=\"token punctuation\">,</span> b_in<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> num_iters<span class=\"token punctuation\">,</span> cost_function<span class=\"token punctuation\">,</span> gradient_function<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  w <span class=\"token operator\">=</span> copy<span class=\"token punctuation\">.</span>deepcopy<span class=\"token punctuation\">(</span>w_in<span class=\"token punctuation\">)</span>\n  J_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  p_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  b <span class=\"token operator\">=</span> b_in\n  w <span class=\"token operator\">=</span> w_in\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    dj_dw<span class=\"token punctuation\">,</span> dj_db <span class=\"token operator\">=</span> gradient_function<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span>\n    b <span class=\"token operator\">=</span> b <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_db\n    w <span class=\"token operator\">=</span> w <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_dw\n\n    <span class=\"token keyword\">if</span> i <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">100000</span><span class=\"token punctuation\">:</span>\n      J_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>cost_function<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>w<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      p_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> J_history<span class=\"token punctuation\">,</span> p_history\n\n\n<span class=\"token comment\"># initialize parameters</span>\nw_init <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nb_init <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token comment\"># some gradient descent settings</span>\niterations <span class=\"token operator\">=</span> <span class=\"token number\">10000</span>\ntmp_alpha <span class=\"token operator\">=</span> <span class=\"token number\">1.0e-2</span>\n<span class=\"token comment\"># run gradient descent</span>\nw_final<span class=\"token punctuation\">,</span> b_final<span class=\"token punctuation\">,</span> J_hist<span class=\"token punctuation\">,</span> p_hist <span class=\"token operator\">=</span> gradient_descent<span class=\"token punctuation\">(</span>x_train <span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span> w_init<span class=\"token punctuation\">,</span> b_init<span class=\"token punctuation\">,</span> tmp_alpha<span class=\"token punctuation\">,</span>\n                                                    iterations<span class=\"token punctuation\">,</span> compute_cost<span class=\"token punctuation\">,</span> compute_gradient<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"(w,b) found by gradient descent: (</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>w_final<span class=\"token punctuation\">:</span><span class=\"token format-spec\">8.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">,</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>b_final<span class=\"token punctuation\">:</span><span class=\"token format-spec\">8.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">)\"</span></span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h5>Multiple Linear Regression</h5>\n<p>Support multiple features</p>\n<p>xj = jth feature\nn = number of features\nx^i = features of the ith training example\nX^ij = value of j feature in ith training example</p>\n<p>model:\nfwb(x) = w1x1 + w2x2 + ... + wnxn + b</p>\n<p>store weights in a row vector\nstore x in a row vector\nb is a single number</p>\n<p>fwb(x) = w dotproduct x + b</p>\n<p>dotproduct is elementwise sum of products</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\">w <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span><span class=\"token number\">2.5</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">3.3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\nx <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span><span class=\"token number\">30</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># computer does product in parallel rather than a serial for loop</span>\nf <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b\n</code></pre></div>\n<h5>Linear Regression by Hand</h5>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> copy<span class=\"token punctuation\">,</span> math\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\nX_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">2104</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">45</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1416</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">852</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">35</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ny_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">460</span><span class=\"token punctuation\">,</span> <span class=\"token number\">232</span><span class=\"token punctuation\">,</span> <span class=\"token number\">178</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nb_init <span class=\"token operator\">=</span> <span class=\"token number\">785.1811367994083</span>\nw_init <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> <span class=\"token number\">0.39133535</span><span class=\"token punctuation\">,</span> <span class=\"token number\">18.75376741</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">53.36032453</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">26.42131618</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">predict_single_loop</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_cost</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  m <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n  cost <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span>\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    f_wb_i <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b\n    cost <span class=\"token operator\">=</span> cost <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>f_wb_i <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token number\">2</span>\n  <span class=\"token keyword\">return</span> cost <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>m<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_gradient</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  m<span class=\"token punctuation\">,</span>n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n  dj_dw <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  dj_db <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    err <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> err <span class=\"token operator\">*</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span>j<span class=\"token punctuation\">]</span>\n    dj_db <span class=\"token operator\">=</span> dj_db <span class=\"token operator\">+</span> err\n\n  <span class=\"token keyword\">return</span> dj_dw <span class=\"token operator\">/</span> m<span class=\"token punctuation\">,</span> dj_db <span class=\"token operator\">/</span> m\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">gradient_descent</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w_in<span class=\"token punctuation\">,</span> b_in<span class=\"token punctuation\">,</span> cost_function<span class=\"token punctuation\">,</span> gradient_function<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> num_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Performs batch gradient descent to learn theta. Updates theta by taking</span>\n<span class=\"token triple-quoted-string string\">    num_iters gradient steps with learning rate alpha</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n))   : Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,))    : target values</span>\n<span class=\"token triple-quoted-string string\">      w_in (ndarray (n,)) : initial model parameters</span>\n<span class=\"token triple-quoted-string string\">      b_in (scalar)       : initial model parameter</span>\n<span class=\"token triple-quoted-string string\">      cost_function       : function to compute cost</span>\n<span class=\"token triple-quoted-string string\">      gradient_function   : function to compute the gradient</span>\n<span class=\"token triple-quoted-string string\">      alpha (float)       : Learning rate</span>\n<span class=\"token triple-quoted-string string\">      num_iters (int)     : number of iterations to run gradient descent</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,)) : Updated values of parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)       : Updated value of parameter</span>\n<span class=\"token triple-quoted-string string\">      \"\"\"</span>\n\n    <span class=\"token comment\"># An array to store cost J and w's at each iteration primarily for graphing later</span>\n    J_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    w <span class=\"token operator\">=</span> copy<span class=\"token punctuation\">.</span>deepcopy<span class=\"token punctuation\">(</span>w_in<span class=\"token punctuation\">)</span>  <span class=\"token comment\">#avoid modifying global w within function</span>\n    b <span class=\"token operator\">=</span> b_in\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        <span class=\"token comment\"># Calculate the gradient and update the parameters</span>\n        dj_db<span class=\"token punctuation\">,</span>dj_dw <span class=\"token operator\">=</span> gradient_function<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span>   <span class=\"token comment\">##None</span>\n\n        <span class=\"token comment\"># Update Parameters using w, b, alpha and gradient</span>\n        w <span class=\"token operator\">=</span> w <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_dw               <span class=\"token comment\">##None</span>\n        b <span class=\"token operator\">=</span> b <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_db               <span class=\"token comment\">##None</span>\n\n        <span class=\"token comment\"># Save cost J at each iteration</span>\n        <span class=\"token keyword\">if</span> i<span class=\"token operator\">&#x3C;</span><span class=\"token number\">100000</span><span class=\"token punctuation\">:</span>      <span class=\"token comment\"># prevent resource exhaustion</span>\n            J_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span> cost_function<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Print cost every at intervals 10 times or as many iterations if &#x3C; 10</span>\n        <span class=\"token keyword\">if</span> i<span class=\"token operator\">%</span> math<span class=\"token punctuation\">.</span>ceil<span class=\"token punctuation\">(</span>num_iters <span class=\"token operator\">/</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Iteration </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">:</span><span class=\"token format-spec\">4d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">: Cost </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>J_history<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">8.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">   \"</span></span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> J_history <span class=\"token comment\">#return final w,b and J history for graphing</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">zscore_normalize_features</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># avg of each column</span>\n  mu <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\"># stddev of each column</span>\n  sigma <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n  X_norm <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>X <span class=\"token operator\">-</span> mu<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> sigma\n  <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">,</span> mu<span class=\"token punctuation\">,</span> sigma<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># initialize parameters</span>\ninitial_w <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros_like<span class=\"token punctuation\">(</span>w_init<span class=\"token punctuation\">)</span>\ninitial_b <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n<span class=\"token comment\"># some gradient descent settings</span>\niterations <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\nalpha <span class=\"token operator\">=</span> <span class=\"token number\">1.0e-1</span>\nX_norm<span class=\"token punctuation\">,</span> mu<span class=\"token punctuation\">,</span> sigma <span class=\"token operator\">=</span> zscore_normalize_Features<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># run gradient descent</span>\nw_final<span class=\"token punctuation\">,</span> b_final<span class=\"token punctuation\">,</span> J_hist <span class=\"token operator\">=</span> gradient_descent<span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> initial_w<span class=\"token punctuation\">,</span> initial_b<span class=\"token punctuation\">,</span>\n                                                    compute_cost<span class=\"token punctuation\">,</span> compute_gradient<span class=\"token punctuation\">,</span>\n                                                    alpha<span class=\"token punctuation\">,</span> iterations<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># to predict new input, normalize the features</span>\nx_house <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1200</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">40</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nx_house_norm <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>x_house <span class=\"token operator\">-</span> X_mu<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> X_sigma\nx_house_predict <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dor<span class=\"token punctuation\">(</span>x_house_norm<span class=\"token punctuation\">,</span> w_final<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b_final\n</code></pre></div>\n<p>Normal equation can be used as an alternative to gradient descent for linear regression without iterations. It doesn't generalize to other learning algorithms and it can be slow for a large number of features.</p>\n<h5>Feature Scaling</h5>\n<p>some inputs can take a large range of values, others a small range of values (ex sqft vs # of bedrooms). Large inputs will likely have small weights, small values will have larger weights. The contour plot of the cost function will be asymmetric signifying small changes in one dimension can have a large impact - takes longer to find a local minima. Scaling features to operate on a similar scale produces a contour plot that is more circular -> a more direct path to the minima can be found.</p>\n<p>can be scaled by input feature/max(feature across all rows)\nalt: mean normalization - (input feature - mean)/(max - min)\nalt: z-score normalization - (input feature - mean)/stddev. After z-score normalization, all features will have a mean of 0 and a standard deviation of 1.</p>\n<p>aim to get features roughly between -1 to 1. Only need to rescale features that are too large or too small.</p>\n<p>Feature scaling will improve the performance of gradient descent since it makes a more direct path to a minimum.</p>\n<h3>Feature Engineering</h3>\n<p>Use intuition to design new features by transforming or combining original features. For example, for housing prices dataset that has lot frontage and depth as separate features, you can create a new feature to represent area.</p>\n<h3>Polynomial Regression</h3>\n<p>If data is nonlinear, polynomial regression can be used to get curved lines. Simply add features that are raised to a power and run linear regression. Gradient descent naturally 'picks' the 'correct' feature by emphasizing its associated weight. The best features will be linear relative to the target (plot X^n against Y to see if linear line is generated).</p>\n<h5>Linear Regression with Scikit-Learn</h5>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> SGDRegressor\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> StandardScalar\n\nscaler <span class=\"token operator\">=</span> StandardScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#z-score normalization</span>\nX_norm <span class=\"token operator\">=</span> scaler<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># selects a sparese subset of features most relevant to the target variable</span>\nsgdr <span class=\"token operator\">=</span> SGDRegressor<span class=\"token punctuation\">(</span>max_iter<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\nsgdr<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># sgdr._n_iter_, sgdr.t_ = number of completed iteration, number of weight updates</span>\nb_norm <span class=\"token operator\">=</span> sgdr<span class=\"token punctuation\">.</span>intercept_\nw_norm <span class=\"token operator\">=</span> sgdr<span class=\"token punctuation\">.</span>coef_\ny_pred_sgd <span class=\"token operator\">=</span> sgdr<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">)</span>\ny_pred <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">,</span> w_norm<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b_norm <span class=\"token comment\"># y_pred = y_pred_sgd</span>\n\n<span class=\"token comment\"># plot predictions and targets vs original features</span>\nfig<span class=\"token punctuation\">,</span>ax<span class=\"token operator\">=</span>plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>sharey<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ax<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    ax<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span> label <span class=\"token operator\">=</span> <span class=\"token string\">'target'</span><span class=\"token punctuation\">)</span>\n    ax<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>y_pred<span class=\"token punctuation\">,</span>color<span class=\"token operator\">=</span>dlc<span class=\"token punctuation\">[</span><span class=\"token string\">\"dlorange\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label <span class=\"token operator\">=</span> <span class=\"token string\">'predict'</span><span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>set_ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"Price\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> ax<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfig<span class=\"token punctuation\">.</span>suptitle<span class=\"token punctuation\">(</span><span class=\"token string\">\"target versus prediction using z-score normalized model\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># alt:</span>\n<span class=\"token comment\"># show the line of best fit in single input variable</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> predicted<span class=\"token punctuation\">,</span> c <span class=\"token operator\">=</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># show a scatter plot of the raw data</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'x'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h5>Categorical data</h5>\n<p>One-hot encoding can be used to represent categorical variables as numerical data.</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\">pd<span class=\"token punctuation\">.</span>get_dummies<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>df<span class=\"token punctuation\">,</span> drop_first<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"remark-highlight\"><pre class=\"language-unknown\"><code class=\"language-unknown\">Color\nred\ngreen\nblue</code></pre></div>\n<p>is converted to:</p>\n<div class=\"remark-highlight\"><pre class=\"language-unknown\"><code class=\"language-unknown\">red green blue\n1   0     0\n0   1     0\n0   0     1</code></pre></div>\n<p>A label encoder can be used to replace categories with a number from 0 to num categories</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n\nencoder <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ncat_col <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train_data<span class=\"token punctuation\">.</span>select_dtypes<span class=\"token punctuation\">(</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  cat_col<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">)</span>\ntrain_data<span class=\"token punctuation\">[</span>cat_col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> encoder<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>cat_col<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"remark-highlight\"><pre class=\"language-unknown\"><code class=\"language-unknown\">Color\nred\ngreen\nblue</code></pre></div>\n<p>is converted to:</p>\n<div class=\"remark-highlight\"><pre class=\"language-unknown\"><code class=\"language-unknown\">Color\n0\n1\n2</code></pre></div>\n<h3>Kaggle</h3>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> StandardScaler\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> SGDRegressor\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error\n<span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBRegressor\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n\n<span class=\"token comment\"># don't replace NA with NaN</span>\ntrain_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'/path/to/csv'</span><span class=\"token punctuation\">,</span> na_filter<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># remove actual NaN rows</span>\ntrain_data<span class=\"token punctuation\">.</span>dropna<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># one-hot encoding</span>\ntrain_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>get_dummies<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>df<span class=\"token punctuation\">,</span> drop_first<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nX <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ny <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">]</span>\n\nx_train<span class=\"token punctuation\">,</span>x_test<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span>y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">,</span>test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span>train_size<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">)</span>\nXG <span class=\"token operator\">=</span> XGBRegressor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nXG<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">)</span>\nscore <span class=\"token operator\">=</span> XG<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>y_test<span class=\"token punctuation\">)</span>\n\nsgdr <span class=\"token operator\">=</span> SGDRegressor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nscaler <span class=\"token operator\">=</span> StandardScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nX_norm <span class=\"token operator\">=</span> scaler<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span>x_test<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span>y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X_norm<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">,</span>test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span>train_size<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">)</span>\nsgdr<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\nscore <span class=\"token operator\">=</span> sgdr<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>y_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> sgdr<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># get the highest correlating features</span>\ncorr_m <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfig2<span class=\"token punctuation\">,</span> ax <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>heatmap<span class=\"token punctuation\">(</span>corr_m<span class=\"token punctuation\">,</span> vmax<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> square<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>cmap<span class=\"token operator\">=</span><span class=\"token string\">\"coolwarm\"</span><span class=\"token punctuation\">,</span>annot<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nhighest_corr_features <span class=\"token operator\">=</span> corr_m<span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">[</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>corr_m<span class=\"token punctuation\">[</span><span class=\"token string\">\"SalePrice\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">]</span>\n</code></pre></div>\n<h3>Classification</h3>\n<p>output variable can take on a small number of possible values</p>\n<p>logistic regression is used to solve classification problems</p>\n<p>examples:\nis email spam?\nis transaction fraudulent?\nis tumor malignant?</p>\n<p>Linear regression is impacted by outliers which can shift the decision boundary/threshold</p>\n<p><img src=\"/images/regression-for-classification.png\" alt=\"linear regression for classification\"></p>\n<p>Logistic regression is used to classify data into 0 and 1. Can use sigmoid function (1 / (1 + e^-z)). (s curve the has y intercept at 0.5, between 0 and 1). Set z = w dotproduct x + b. Result can be thought of as the probabilit that class is 1.</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">sigmoid</span><span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  g <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">+</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>z<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> g\n</code></pre></div>\n<p>If a threshold of 0.5 is used, model predicts 1 when w dotproduct x + b >= 0. For non-linear decision boundaries, use same principles of polynomial regression.</p>\n<p>Sum of squared errors is not a good cost function for logistic regression because its not a convex - gradient descent will fall into a local minimum, not the global minimum.</p>\n<p>Instead, use logistic loss function which is convex and can reach a global minimum:</p>\n<p><img src=\"/images/logistic-loss.png\" alt=\"Logistic Loss\">\n<img src=\"/images/logistic-loss-negative.png\" alt=\"Logicistic Loss Negative Case\">\n<img src=\"/images/simplified-loss.png\" alt=\"Simplified Loss\"></p>\n<p>Logistic Cost function:\n<img src=\"/images/logistic-cost.png\" alt=\"Logistic Cost\"></p>\n<p>Gradient Descent\n<img src=\"/images/gradient-descent-logicistic-regression.png\" alt=\"Gradient Descent for Logistic Regression\"></p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">compute_gradient_logistic</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  m<span class=\"token punctuation\">,</span>n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n  dj_dw <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  dj_db <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    f_wb_i <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n    err_i <span class=\"token operator\">=</span> f_wb_i <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> err_i <span class=\"token operator\">*</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span>j<span class=\"token punctuation\">]</span>\n    dj_db <span class=\"token operator\">=</span> dj_db <span class=\"token operator\">+</span> err_i\n  dj_dw <span class=\"token operator\">=</span> dj_dw<span class=\"token operator\">/</span>m\n  dj_db <span class=\"token operator\">=</span> dj_db<span class=\"token operator\">/</span>m\n  <span class=\"token keyword\">return</span> dj_db<span class=\"token punctuation\">,</span> dj_dw\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">gradient_descent</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w_in<span class=\"token punctuation\">,</span> b_in<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> num_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Performs batch gradient descent</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n)   : Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,))   : target values</span>\n<span class=\"token triple-quoted-string string\">      w_in (ndarray (n,)): Initial values of model parameters</span>\n<span class=\"token triple-quoted-string string\">      b_in (scalar)      : Initial values of model parameter</span>\n<span class=\"token triple-quoted-string string\">      alpha (float)      : Learning rate</span>\n<span class=\"token triple-quoted-string string\">      num_iters (scalar) : number of iterations to run gradient descent</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,))   : Updated values of parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)         : Updated value of parameter</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n    <span class=\"token comment\"># An array to store cost J and w's at each iteration primarily for graphing later</span>\n    J_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    w <span class=\"token operator\">=</span> copy<span class=\"token punctuation\">.</span>deepcopy<span class=\"token punctuation\">(</span>w_in<span class=\"token punctuation\">)</span>  <span class=\"token comment\">#avoid modifying global w within function</span>\n    b <span class=\"token operator\">=</span> b_in\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Calculate the gradient and update the parameters</span>\n        dj_db<span class=\"token punctuation\">,</span> dj_dw <span class=\"token operator\">=</span> compute_gradient_logistic<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Update Parameters using w, b, alpha and gradient</span>\n        w <span class=\"token operator\">=</span> w <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_dw\n        b <span class=\"token operator\">=</span> b <span class=\"token operator\">-</span> alpha <span class=\"token operator\">*</span> dj_db\n\n        <span class=\"token comment\"># Save cost J at each iteration</span>\n        <span class=\"token keyword\">if</span> i<span class=\"token operator\">&#x3C;</span><span class=\"token number\">100000</span><span class=\"token punctuation\">:</span>      <span class=\"token comment\"># prevent resource exhaustion</span>\n            J_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span> compute_cost_logistic<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Print cost every at intervals 10 times or as many iterations if &#x3C; 10</span>\n        <span class=\"token keyword\">if</span> i<span class=\"token operator\">%</span> math<span class=\"token punctuation\">.</span>ceil<span class=\"token punctuation\">(</span>num_iters <span class=\"token operator\">/</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Iteration </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">:</span><span class=\"token format-spec\">4d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">: Cost </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>J_history<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">   \"</span></span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> J_history         <span class=\"token comment\">#return final w,b and J history for graphing</span>\n\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LogisticRegression\n\nlr_model <span class=\"token operator\">=</span> LogisticRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlr_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\ny_pred <span class=\"token operator\">=</span> lr_model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Accuracy on training set:\"</span><span class=\"token punctuation\">,</span> lr_model<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Overfitting</h3>\n<p>underfitting = model does not fit the training set well. High bias.\ngeneralization = fits training set and brand new examples well.\noverfitting = model fits the training set extremely well but will not generalize to new examples. High variance.</p>\n<p>Overfitting can be addressed by:</p>\n<ol>\n<li>collecting more training examples.</li>\n<li>Use fewer features</li>\n<li>Regularization - reduce the size of weights. Makes the line smoother.</li>\n</ol>\n<p><img src=\"/images/regularization.png\" alt=\"Regularization\"></p>\n<p><img src=\"/images/regularizedgradientdescent.png\" alt=\"Regularized Gradient Descent\"></p>\n<p>above minimizes the mean squared error while trying to keep wj small.</p>\n<p>If lambda is 0, model overfits. If lambda is very large, model underfits (f(x) = b).</p>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">compute_cost_linear_reg</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> lambda_ <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Computes the cost over all examples</span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n): Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,)): target values</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,)): model parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)      : model parameter</span>\n<span class=\"token triple-quoted-string string\">      lambda_ (scalar): Controls amount of regularization</span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">      total_cost (scalar):  cost</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    m  <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    n  <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">)</span>\n    cost <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        f_wb_i <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b                                   <span class=\"token comment\">#(n,)(n,)=scalar, see np.dot</span>\n        cost <span class=\"token operator\">=</span> cost <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>f_wb_i <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token number\">2</span>                               <span class=\"token comment\">#scalar</span>\n    cost <span class=\"token operator\">=</span> cost <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> m<span class=\"token punctuation\">)</span>                                              <span class=\"token comment\">#scalar</span>\n\n    reg_cost <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        reg_cost <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token operator\">**</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>                                          <span class=\"token comment\">#scalar</span>\n    reg_cost <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>lambda_<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> reg_cost                              <span class=\"token comment\">#scalar</span>\n\n    total_cost <span class=\"token operator\">=</span> cost <span class=\"token operator\">+</span> reg_cost                                       <span class=\"token comment\">#scalar</span>\n    <span class=\"token keyword\">return</span> total_cost\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_cost_logistic_reg</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> lambda_ <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Computes the cost over all examples</span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n): Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,)): target values</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,)): model parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)      : model parameter</span>\n<span class=\"token triple-quoted-string string\">      lambda_ (scalar): Controls amount of regularization</span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">      total_cost (scalar):  cost</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n\n    m<span class=\"token punctuation\">,</span>n  <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n    cost <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        z_i <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b                                      <span class=\"token comment\">#(n,)(n,)=scalar, see np.dot</span>\n        f_wb_i <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>z_i<span class=\"token punctuation\">)</span>                                          <span class=\"token comment\">#scalar</span>\n        cost <span class=\"token operator\">+=</span>  <span class=\"token operator\">-</span>y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>f_wb_i<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span>np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>f_wb_i<span class=\"token punctuation\">)</span>      <span class=\"token comment\">#scalar</span>\n\n    cost <span class=\"token operator\">=</span> cost<span class=\"token operator\">/</span>m                                                      <span class=\"token comment\">#scalar</span>\n\n    reg_cost <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        reg_cost <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token operator\">**</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>                                          <span class=\"token comment\">#scalar</span>\n    reg_cost <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>lambda_<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> reg_cost                              <span class=\"token comment\">#scalar</span>\n\n    total_cost <span class=\"token operator\">=</span> cost <span class=\"token operator\">+</span> reg_cost                                       <span class=\"token comment\">#scalar</span>\n    <span class=\"token keyword\">return</span> total_cost                                                  <span class=\"token comment\">#scalar</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_gradient_linear_reg</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> lambda_<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Computes the gradient for linear regression</span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n): Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,)): target values</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,)): model parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)      : model parameter</span>\n<span class=\"token triple-quoted-string string\">      lambda_ (scalar): Controls amount of regularization</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Returns:</span>\n<span class=\"token triple-quoted-string string\">      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w.</span>\n<span class=\"token triple-quoted-string string\">      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b.</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n    m<span class=\"token punctuation\">,</span>n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape           <span class=\"token comment\">#(number of examples, number of features)</span>\n    dj_dw <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    dj_db <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        err <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> err <span class=\"token operator\">*</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">]</span>\n        dj_db <span class=\"token operator\">=</span> dj_db <span class=\"token operator\">+</span> err\n    dj_dw <span class=\"token operator\">=</span> dj_dw <span class=\"token operator\">/</span> m\n    dj_db <span class=\"token operator\">=</span> dj_db <span class=\"token operator\">/</span> m\n\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>lambda_<span class=\"token operator\">/</span>m<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> w<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">return</span> dj_db<span class=\"token punctuation\">,</span> dj_dw\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_gradient_logistic_reg</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> lambda_<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"</span>\n<span class=\"token triple-quoted-string string\">    Computes the gradient for linear regression</span>\n<span class=\"token triple-quoted-string string\"></span>\n<span class=\"token triple-quoted-string string\">    Args:</span>\n<span class=\"token triple-quoted-string string\">      X (ndarray (m,n): Data, m examples with n features</span>\n<span class=\"token triple-quoted-string string\">      y (ndarray (m,)): target values</span>\n<span class=\"token triple-quoted-string string\">      w (ndarray (n,)): model parameters</span>\n<span class=\"token triple-quoted-string string\">      b (scalar)      : model parameter</span>\n<span class=\"token triple-quoted-string string\">      lambda_ (scalar): Controls amount of regularization</span>\n<span class=\"token triple-quoted-string string\">    Returns</span>\n<span class=\"token triple-quoted-string string\">      dj_dw (ndarray Shape (n,)): The gradient of the cost w.r.t. the parameters w.</span>\n<span class=\"token triple-quoted-string string\">      dj_db (scalar)            : The gradient of the cost w.r.t. the parameter b.</span>\n<span class=\"token triple-quoted-string string\">    \"\"\"</span>\n    m<span class=\"token punctuation\">,</span>n <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>shape\n    dj_dw <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>                            <span class=\"token comment\">#(n,)</span>\n    dj_db <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span>                                       <span class=\"token comment\">#scalar</span>\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        f_wb_i <span class=\"token operator\">=</span> sigmoid<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>          <span class=\"token comment\">#(n,)(n,)=scalar</span>\n        err_i  <span class=\"token operator\">=</span> f_wb_i  <span class=\"token operator\">-</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>                       <span class=\"token comment\">#scalar</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> err_i <span class=\"token operator\">*</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span>j<span class=\"token punctuation\">]</span>      <span class=\"token comment\">#scalar</span>\n        dj_db <span class=\"token operator\">=</span> dj_db <span class=\"token operator\">+</span> err_i\n    dj_dw <span class=\"token operator\">=</span> dj_dw<span class=\"token operator\">/</span>m                                   <span class=\"token comment\">#(n,)</span>\n    dj_db <span class=\"token operator\">=</span> dj_db<span class=\"token operator\">/</span>m                                   <span class=\"token comment\">#scalar</span>\n\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> dj_dw<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>lambda_<span class=\"token operator\">/</span>m<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> w<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">return</span> dj_db<span class=\"token punctuation\">,</span> dj_dw\n</code></pre></div>\n<h1>Numpy</h1>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token comment\"># vector creation</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># returns vector of 4 elements from 0-1</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>random_sample<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\nreturns vector of <span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>rand<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># one row of five elements</span>\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># vectors have a shape property</span>\na<span class=\"token punctuation\">.</span>shape\n<span class=\"token comment\"># slicing is done with start:stop:step</span>\na<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token number\">7</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\na<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\na<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\na<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token number\">7</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># operations</span>\nnp<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\nnp<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\na<span class=\"token operator\">**</span><span class=\"token number\">2</span>\n<span class=\"token comment\"># element-wise sum/product</span>\na <span class=\"token operator\">+</span> a\na <span class=\"token operator\">*</span> <span class=\"token number\">5</span>\n</code></pre></div>\n<h1>Pandas</h1>\n<h3>I/O</h3>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span>\noutput <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">'Id'</span><span class=\"token punctuation\">:</span> test_data<span class=\"token punctuation\">.</span>Id<span class=\"token punctuation\">,</span>\n                       <span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">:</span> test_preds<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\noutput<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'submission.csv'</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h3>Common Operations</h3>\n<div class=\"remark-highlight\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\n<span class=\"token comment\"># table with two rows, columns YES and NO</span>\n<span class=\"token comment\"># index is the row label, if not provided, uses 0...n-1 by default</span>\npd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">'Yes'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'No'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token number\">131</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Product 1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Product 2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># sequence/list of values, can be thought of as single column</span>\npd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'2015 sales'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'2016 sales'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'Product Sales'</span><span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'path/to/csv.csv'</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token operator\">&#x3C;</span><span class=\"token number\">0</span> to n<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token operator\">></span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># (&#x3C;rows>, &#x3C;columns>)</span>\ndata<span class=\"token punctuation\">.</span>shape\n\ndata<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'path/to/write.csv'</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># column access</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'column name'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># row access</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'column name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># first three rows of first column</span>\ndata<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># first three rows of column name</span>\ndata<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'column name'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># all rows for n columns</span>\ndata<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'col1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'col2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># change the index</span>\ndata<span class=\"token punctuation\">.</span>set_index<span class=\"token punctuation\">(</span><span class=\"token string\">'col1'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># querying</span>\ndata<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">'foobar'</span> <span class=\"token operator\">&#x26;</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'colX'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isin<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>val1<span class=\"token punctuation\">,</span> val2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x26;</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'colN'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>notnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x26;</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'col2'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">10</span> <span class=\"token operator\">|</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'col3'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># assignment</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'FOO'</span>\n\n<span class=\"token comment\"># if numerical, shows percentiles</span>\n<span class=\"token comment\"># if string, shows uniques, top, count</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>describe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># frequency table</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># alt for above</span>\ndata<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># returns all unique values in col</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># doesnt mutate existing data frame</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> v<span class=\"token punctuation\">:</span> v <span class=\"token operator\">+</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># equiv to above</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">100</span>\n\n<span class=\"token comment\"># the index of the row with the max col name</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>idxmax<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># calls func_name with row</span>\n<span class=\"token comment\"># if axis='index', calls func_name for each column</span>\n<span class=\"token comment\"># returns new dataframe, doesn't mutate existing</span>\ndata<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func_name<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token string\">'columns'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># min price for each point category</span>\nreviews<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'points'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>price<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># best wine for country/province</span>\nreviews<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'province'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> df<span class=\"token punctuation\">:</span> df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span>df<span class=\"token punctuation\">.</span>points<span class=\"token punctuation\">.</span>idxmax<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nreviews<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>price<span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># make multi-index back to single index</span>\ncountries_reviewed <span class=\"token operator\">=</span> reviews<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'province'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>description<span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ncountries_reviewed <span class=\"token operator\">=</span> countries_reviewed<span class=\"token punctuation\">.</span>reset_index<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncountries_reviewed<span class=\"token punctuation\">.</span>sort_values<span class=\"token punctuation\">(</span>by<span class=\"token operator\">=</span><span class=\"token string\">'len'</span><span class=\"token punctuation\">,</span> ascending<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\ncountries_reviewed<span class=\"token punctuation\">.</span>sort_values<span class=\"token punctuation\">(</span>by<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'len'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nbest_rating_per_price <span class=\"token operator\">=</span> reviews<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'points'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sort_index<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># strings are of type object</span>\nreviews<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dtype\n<span class=\"token comment\"># data frame of column -> type</span>\nreviews<span class=\"token punctuation\">.</span>dtypes\n<span class=\"token comment\"># cast column to another type</span>\nreviews<span class=\"token punctuation\">[</span><span class=\"token string\">'col name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float64'</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># get all reviews with null column</span>\nreviews<span class=\"token punctuation\">[</span>pd<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span>reviews<span class=\"token punctuation\">[</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\nreviews<span class=\"token punctuation\">.</span>country<span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token string\">'some val'</span><span class=\"token punctuation\">)</span>\nreviews<span class=\"token punctuation\">.</span>country<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'from'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'to'</span><span class=\"token punctuation\">)</span>\n\nreviews<span class=\"token punctuation\">.</span>rename<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'country'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'somethingelse'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># put labels on each axis</span>\nreviews<span class=\"token punctuation\">.</span>rename_axis<span class=\"token punctuation\">(</span><span class=\"token string\">\"wines\"</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token string\">'rows'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rename_axis<span class=\"token punctuation\">(</span><span class=\"token string\">\"fields\"</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token string\">'columns'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># combine rows of df1 and df2 in new df</span>\npd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>df1<span class=\"token punctuation\">,</span> df2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nleft <span class=\"token operator\">=</span> canadian_youtube<span class=\"token punctuation\">.</span>set_index<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'trending_date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nright <span class=\"token operator\">=</span> british_youtube<span class=\"token punctuation\">.</span>set_index<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'trending_date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nleft<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>right<span class=\"token punctuation\">,</span> lsuffix<span class=\"token operator\">=</span><span class=\"token string\">'_CAN'</span><span class=\"token punctuation\">,</span> rsuffix<span class=\"token operator\">=</span><span class=\"token string\">'_UK'</span><span class=\"token punctuation\">)</span>\npowerlifting_combined <span class=\"token operator\">=</span> powerlifting_meets<span class=\"token punctuation\">.</span>set_index<span class=\"token punctuation\">(</span><span class=\"token string\">\"MeetID\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>powerlifting_competitors<span class=\"token punctuation\">.</span>set_index<span class=\"token punctuation\">(</span><span class=\"token string\">\"MeetID\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>next:\nhttps://www.coursera.org/projects/used-car-price-prediction-using-machine-learning-models</p>\n<p>https://developers.google.com/machine-learning/crash-course</p>\n<p>https://course.fast.ai/</p>\n<p>https://courses.dataschool.io/</p>\n<p>https://www.coursera.org/learn/machine-learning</p>\n<p>https://www.amazon.ca/Grokking-Machine-Learning-Luis-Serrano/dp/1617295914</p>\n<p>https://www.amazon.ca/Grokking-Artificial-Intelligence-Algorithms-Hurbans/dp/161729618X/ref=pd_lpo_2?pd_rd_w=2IkSF&#x26;content-id=amzn1.sym.bc8b374c-8130-4c45-bf24-4fcc0d96f4d6&#x26;pf_rd_p=bc8b374c-8130-4c45-bf24-4fcc0d96f4d6&#x26;pf_rd_r=50QQ4KNVZFECYAE6ZK4Y&#x26;pd_rd_wg=4gcj6&#x26;pd_rd_r=df9b5ab5-7424-43b0-a89b-1429044164f8&#x26;pd_rd_i=161729618X&#x26;psc=1</p>\n<p>https://www.amazon.ca/Grokking-Deep-Learning-Andrew-Trask/dp/1617293709/ref=pd_bxgy_sccl_1/139-6089511-3105238?pd_rd_w=Nenof&#x26;content-id=amzn1.sym.17b2b149-58e2-4824-ba79-851c5f351fdc&#x26;pf_rd_p=17b2b149-58e2-4824-ba79-851c5f351fdc&#x26;pf_rd_r=50QQ4KNVZFECYAE6ZK4Y&#x26;pd_rd_wg=HJRUU&#x26;pd_rd_r=85270beb-f7ff-4720-b6b0-e8165b411269&#x26;pd_rd_i=1617293709&#x26;psc=1</p>\n<p>Learn about scikit learn GridSearchCV</p>\n<p>https://e2eml.school/blog.html</p>\n<p>https://cds.nyu.edu/deep-learning/</p>\n<p>https://ocw.mit.edu/courses/18-06sc-linear-algebra-fall-2011/</p>\n<p>https://github.com/oxford-cs-deepnlp-2017</p>\n<h3>Problems</h3>\n<p>use speech recognition principles to build a wav -> midi maker\nbuild a mike tysons punch out solver\nmake a deepfake to put your face throughout history\ncrawl every Dataphile spec and make it searchable</p>\n<h3>Questions</h3>\n<p>which features should I use? Maybe use GridSearchCV?\nhow do I know if I need to engineer features?\nwhat do you do with dates?\nhow do you with deal with NaNs?\nhow do you do non-binary classification?</p>\n"}},"__N_SSG":true}